#!/usr/bin/env python3
"""
HTTPè®¾å¤‡è·¯å¾„å‘ç°å·¥å…·
ç”¨äºæ¢æµ‹HTTPç›‘æ§è®¾å¤‡çš„å¯ç”¨è·¯å¾„
"""

import requests
import sys
import time
from urllib.parse import urljoin

def test_device_url(ip, port, paths):
    """æµ‹è¯•è®¾å¤‡çš„ä¸åŒè·¯å¾„"""
    base_url = f"http://{ip}:{port}"
    
    print(f"æ­£åœ¨æµ‹è¯•è®¾å¤‡: {base_url}")
    print("=" * 50)
    
    common_paths = [
        "", "/", "/login", "/web", "/doc", "/home", "/index",
        "/ISAPI", "/ISAPI/Streaming/channels/101", "/ISAPI/System/deviceInfo",
        "/cam/realmonitor", "/axis-cgi/mjpg/video.cgi", "/video.mjpg",
        "/cgi-bin/mjpg/video.cgi", "/mjpg/video.mjpg", "/snapshot.cgi",
        "/web/recorder.html", "/view/viewer_index.shtml", "/main.html",
        "/admin", "/admin/index.html", "/user/login", "/auth/login"
    ]
    
    # åˆå¹¶ç”¨æˆ·æŒ‡å®šçš„è·¯å¾„
    if paths:
        test_paths = paths + common_paths
    else:
        test_paths = common_paths
    
    # å»é‡
    test_paths = list(set(test_paths))
    
    results = []
    
    for path in test_paths:
        url = urljoin(base_url, path)
        try:
            print(f"æµ‹è¯•: {url}")
            
            # è®¾ç½®è¶…æ—¶å’Œè¯·æ±‚å¤´
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=5, allow_redirects=True)
            
            status = response.status_code
            content_type = response.headers.get('content-type', 'unknown')
            content_length = len(response.content)
            
            result = {
                'url': url,
                'status': status,
                'content_type': content_type,
                'content_length': content_length,
                'title': 'N/A'
            }
            
            # å°è¯•æå–é¡µé¢æ ‡é¢˜
            if 'text/html' in content_type and status == 200:
                try:
                    import re
                    title_match = re.search(r'<title[^>]*>([^<]+)</title>', response.text, re.IGNORECASE)
                    if title_match:
                        result['title'] = title_match.group(1).strip()
                except:
                    pass
            
            results.append(result)
            
            print(f"  çŠ¶æ€: {status} | ç±»å‹: {content_type} | å¤§å°: {content_length} bytes")
            if result['title'] != 'N/A':
                print(f"  æ ‡é¢˜: {result['title']}")
            
            time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
            
        except requests.exceptions.Timeout:
            print(f"  è¶…æ—¶")
        except requests.exceptions.ConnectionError:
            print(f"  è¿æ¥å¤±è´¥")
        except Exception as e:
            print(f"  é”™è¯¯: {str(e)}")
    
    return results

def analyze_results(results):
    """åˆ†ææµ‹è¯•ç»“æœ"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœåˆ†æ:")
    print("=" * 50)
    
    # æŒ‰çŠ¶æ€ç åˆ†ç»„
    status_groups = {}
    for result in results:
        status = result['status']
        if status not in status_groups:
            status_groups[status] = []
        status_groups[status].append(result)
    
    # æ˜¾ç¤ºæˆåŠŸå“åº”
    if 200 in status_groups:
        print("\nâœ… æˆåŠŸå“åº” (200):")
        for result in status_groups[200]:
            print(f"  {result['url']} - {result['title']}")
    
    # æ˜¾ç¤ºé‡å®šå‘
    redirects = [301, 302, 303, 307, 308]
    for code in redirects:
        if code in status_groups:
            print(f"\nğŸ”„ é‡å®šå‘ ({code}):")
            for result in status_groups[code]:
                print(f"  {result['url']}")
    
    # æ˜¾ç¤ºè®¤è¯è¦æ±‚
    if 401 in status_groups:
        print("\nğŸ” éœ€è¦è®¤è¯ (401):")
        for result in status_groups[401]:
            print(f"  {result['url']}")
    
    # æ˜¾ç¤ºæœªæ‰¾åˆ°
    if 404 in status_groups:
        print("\nâŒ æœªæ‰¾åˆ° (404):")
        for result in status_groups[404]:
            print(f"  {result['url']}")
    
    # æ¨èæœ€ä½³è·¯å¾„
    successful = [r for r in results if r['status'] == 200]
    if successful:
        print("\nğŸ† æ¨èè®¿é—®è·¯å¾„:")
        # ä¼˜å…ˆé€‰æ‹©HTMLé¡µé¢
        html_pages = [r for r in successful if 'text/html' in r['content_type']]
        if html_pages:
            for page in html_pages[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"  {page['url']} ({page['title']})")
        else:
            for page in successful[:3]:
                print(f"  {page['url']}")

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python discover_http_paths.py <IPåœ°å€> <ç«¯å£> [è·¯å¾„1] [è·¯å¾„2] ...")
        print("ç¤ºä¾‹: python discover_http_paths.py 192.168.42.86 55501")
        return
    
    ip = sys.argv[1]
    port = int(sys.argv[2])
    custom_paths = sys.argv[3:] if len(sys.argv) > 3 else None
    
    try:
        results = test_device_url(ip, port, custom_paths)
        analyze_results(results)
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        import json
        with open(f'http_paths_{ip}_{port}.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: http_paths_{ip}_{port}.json")
        
    except KeyboardInterrupt:
        print("\næµ‹è¯•è¢«ä¸­æ–­")
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()